{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the meme IDs, text and path to get the image caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXIST 2024\n",
    "exist_training_file = \"../datasets/EXIST2021-2024_datasets/2024 EXIST/EXIST 2024 Memes Dataset/training/EXIST2024_training.json\"\n",
    "exist_test_file = \"../datasets/EXIST2021-2024_datasets/2024 EXIST/EXIST 2024 Memes Dataset/test/EXIST2024_test_clean.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAMI\n",
    "mami_training_file = \"../datasets/MAMI DATASET/TRAINING/training.csv\"\n",
    "mami_test_file = \"../datasets/MAMI DATASET/test/Test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"dataset\": {\"EXIST2024\": {}, \"MAMI\": {}}}\n",
    "\n",
    "#EXIST\n",
    "#training\n",
    "exist_train_data_dict = preprocess_exist(exist_training_file)\n",
    "data[\"dataset\"][\"EXIST2024\"][\"training\"] = exist_train_data_dict\n",
    "\n",
    "#test\n",
    "exist_test_data_dict = preprocess_exist(exist_test_file,\"test\")\n",
    "data[\"dataset\"][\"EXIST2024\"][\"test\"] = exist_test_data_dict\n",
    "\n",
    "#MAMI\n",
    "#training\n",
    "mami_train_data_dict = preprocess_mami(mami_training_file)\n",
    "data[\"dataset\"][\"MAMI\"][\"training\"] = mami_train_data_dict\n",
    "\n",
    "#test\n",
    "mami_test_data_dict = preprocess_mami(mami_test_file,\"test\")\n",
    "data[\"dataset\"][\"MAMI\"][\"test\"] = mami_test_data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets.json is saved\n"
     ]
    }
   ],
   "source": [
    "write_to_json(data,\"datasets.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing after getting image captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_flan_coco = \"datasets_with_captions_blip2-flan-coco_np.json\"\n",
    "captions_after_cleaning = \"datasets_with_captions_after_cleaning.json\"\n",
    "captions_to_redo = \"datasets_with_captions_to_redo_flan-coco.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data with cleaned image captions...\n",
      "datasets_with_captions_after_cleaning.json is saved\n",
      "\n",
      "Saving data to redo image captions...\n",
      "datasets_with_captions_to_redo_flan-coco.json is saved\n"
     ]
    }
   ],
   "source": [
    "removed_phrases = get_cleaned_data_and_instances_to_reprocess(dataset_flan_coco, dataset_flan_coco, captions_after_cleaning, captions_to_redo, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total captions that contained text from meme: 4021\n",
      "\n",
      "Phrase: with the words \t\t Total: 59\n",
      "Phrase: with the caption \t\t Total: 424\n",
      "Phrase: with a caption \t\t Total: 2422\n",
      "Phrase: with the text \t\t Total: 35\n",
      "Phrase: with a text \t\t Total: 47\n",
      "Phrase: with a quote \t\t Total: 121\n",
      "Phrase: with a message \t\t Total: 69\n",
      "Phrase: with text saying \t\t Total: 40\n",
      "Phrase: with text that says \t\t Total: 43\n",
      "Phrase: and a caption \t\t Total: 719\n",
      "Phrase: and a sign that says \t\t Total: 11\n",
      "Phrase: and a quote that says \t\t Total: 1\n",
      "Phrase: and a text that says \t\t Total: 1\n",
      "Phrase: and a text saying \t\t Total: 10\n",
      "Phrase: and text that says \t\t Total: 7\n",
      "Phrase: and the caption says \t\t Total: 1\n",
      "Phrase: and saying \t\t Total: 9\n",
      "Phrase: with a funny meme \t\t Total: 2\n"
     ]
    }
   ],
   "source": [
    "print_removed_phrases(removed_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memes to re-do image captioning: 115\n"
     ]
    }
   ],
   "source": [
    "#how many memes are left to re-do image captioning\n",
    "#empty set to store the meme IDs\n",
    "redo_meme_ids = []\n",
    "\n",
    "with open(captions_to_redo, \"r\", encoding=\"utf8\") as fl:\n",
    "        content = json.load(fl)\n",
    "\n",
    "for dataset in content.values():\n",
    "        for split in dataset.values():\n",
    "            for memes in split.values():\n",
    "                for meme_info in memes.values():\n",
    "                    meme_text = meme_info[\"meme text\"].lower()\n",
    "                    meme_id = meme_info[\"meme id\"]\n",
    "                    redo_meme_ids.append(meme_id)\n",
    "\n",
    "print(f\"Memes to re-do image captioning: {len(redo_meme_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After getting image captions, get representation for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After getting image captions:\n",
    "data_with_captions = \"datasets_with_captions_final.json\"\n",
    "#get text representation for svm and bert models\n",
    "preprocessed_data = generate_text_caption_representations(data_with_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved EXIST2024 training split to datasets/EXIST2024_training.json\n",
      "Saved EXIST2024 test split to datasets/EXIST2024_test.json\n",
      "Saved MAMI training split to datasets/MAMI_training.json\n",
      "Saved MAMI test split to datasets/MAMI_test.json\n"
     ]
    }
   ],
   "source": [
    "#split the datasets into training and test for both MAMI and EXIST\n",
    "process_and_save_splits(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include labels into datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved MAMI training split to datasets/MAMI_training.json\n",
      "Saved EXIST2024 training split to datasets/EXIST2024_training.json\n",
      "Saved MAMI test split to datasets/MAMI_test.json\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"MAMI\", \"EXIST2024\"]\n",
    "for dataset in datasets:\n",
    "    add_labels(dataset, \"training\")\n",
    "add_labels(\"MAMI\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include meme paths into the final datasets! (10-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_meme_paths = \"datasets_with_captions_final.json\"\n",
    "\n",
    "mami_training_data = \"../data/MAMI/MAMI_training.json\"\n",
    "mami_val_data = \"../data/MAMI/MAMI_validation.json\"\n",
    "mami_test_data = \"../preprocessing/datasets/MAMI_test.json\"\n",
    "\n",
    "exist_training_data = \"../data/EXIST2024/EXIST2024_training.json\"\n",
    "exist_val_data = \"../data/EXIST2024/EXIST2024_validation.json\"\n",
    "exist_test_data = \"../data/EXIST2024/EXIST2024_test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../data/MAMI/MAMI_training.json with image paths\n",
      "Saved ../data/MAMI/MAMI_validation.json with image paths\n",
      "Saved ../preprocessing/datasets/MAMI_test.json with image paths\n",
      "Saved ../data/EXIST2024/EXIST2024_training.json with image paths\n",
      "Saved ../data/EXIST2024/EXIST2024_validation.json with image paths\n",
      "Saved ../data/EXIST2024/EXIST2024_test.json with image paths\n"
     ]
    }
   ],
   "source": [
    "add_meme_path(file_with_meme_paths,mami_training_data)\n",
    "add_meme_path(file_with_meme_paths,mami_val_data)\n",
    "add_meme_path(file_with_meme_paths,mami_test_data)\n",
    "add_meme_path(file_with_meme_paths,exist_training_data)\n",
    "add_meme_path(file_with_meme_paths,exist_val_data)\n",
    "add_meme_path(file_with_meme_paths,exist_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
